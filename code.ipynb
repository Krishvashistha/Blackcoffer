{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1hyShOR/qeSTIZnok8r4e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishvashistha/Blackcoffer/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FNrjHt-6oax",
        "outputId": "88ccc7cf-a09d-4f96-b987-4ecb5ddba90c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4 pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZXh0IR17W2Q",
        "outputId": "00c7bb0c-99e5-49f8-9572-2121fb9dd50d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Upload the Input.xlsx file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Read the input file\n",
        "input_df = pd.read_excel('/content/drive/MyDrive/20211030 Test Assignment-20240712T071711Z-001/20211030 Test Assignment/Input.xlsx')\n",
        "\n",
        "# Function to extract article text\n",
        "def extract_article_text(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Assuming article text is within <article> tags (modify as needed)\n",
        "    article = soup.find('article')\n",
        "    if article:\n",
        "        title = article.find('h1').get_text(strip=True)\n",
        "        paragraphs = article.find_all('p')\n",
        "        article_text = '\\n'.join([p.get_text(strip=True) for p in paragraphs])\n",
        "        return title, article_text\n",
        "    return None, None\n",
        "\n",
        "# Extract and save articles\n",
        "for idx, row in input_df.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "    title, article_text = extract_article_text(url)\n",
        "    if article_text:\n",
        "        with open(f\"{url_id}.txt\", 'w', encoding='utf-8') as file:\n",
        "            file.write(f\"{title}\\n\\n{article_text}\")\n",
        "\n",
        "print(\"Extraction complete!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "WYPYqndT7anz",
        "outputId": "adb700b5-82c7-4a44-85fd-cabeb636367e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-73a68210-9017-46b2-a40a-f52f12fe0e31\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-73a68210-9017-46b2-a40a-f52f12fe0e31\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Input.xlsx to Input.xlsx\n",
            "Extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob pyphen pandas\n",
        "!python -m textblob.download_corpora\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Axi_FuSVVox",
        "outputId": "d05aaad1-cf38-4505-aed6-2ea6080c378c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Collecting pyphen\n",
            "  Downloading pyphen-0.15.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: pyphen\n",
            "Successfully installed pyphen-0.15.0\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List extracted files\n",
        "extracted_files = [f for f in os.listdir() if f.endswith('.txt')]\n",
        "print(\"Extracted files:\", extracted_files)\n",
        "\n",
        "# Display content of an example file\n",
        "with open(extracted_files[50], 'r', encoding='utf-8') as file:\n",
        "    print(file.read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dScWc7n29wq8",
        "outputId": "def62586-b2f6-4efa-f268-9a5b49266d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['bctech2129.txt', 'bctech2086.txt', 'bctech2034.txt', 'bctech2135.txt', 'bctech2049.txt', 'bctech2138.txt', 'bctech2084.txt', 'bctech2142.txt', 'bctech2025.txt', 'bctech2083.txt', 'bctech2108.txt', 'bctech2080.txt', 'bctech2013.txt', 'bctech2132.txt', 'bctech2089.txt', 'bctech2063.txt', 'bctech2094.txt', 'bctech2146.txt', 'bctech2053.txt', 'bctech2012.txt', 'bctech2082.txt', 'bctech2011.txt', 'bctech2145.txt', 'bctech2033.txt', 'bctech2079.txt', 'bctech2139.txt', 'bctech2031.txt', 'bctech2058.txt', 'bctech2076.txt', 'bctech2073.txt', 'bctech2150.txt', 'bctech2119.txt', 'bctech2114.txt', 'bctech2090.txt', 'bctech2036.txt', 'bctech2097.txt', 'bctech2037.txt', 'bctech2151.txt', 'bctech2130.txt', 'bctech2134.txt', 'bctech2064.txt', 'bctech2068.txt', 'bctech2121.txt', 'bctech2111.txt', 'bctech2066.txt', 'bctech2126.txt', 'bctech2020.txt', 'bctech2107.txt', 'bctech2050.txt', 'bctech2055.txt', 'bctech2155.txt', 'bctech2022.txt', 'bctech2087.txt', 'bctech2116.txt', 'bctech2118.txt', 'bctech2017.txt', 'bctech2023.txt', 'bctech2106.txt', 'bctech2110.txt', 'bctech2112.txt', 'bctech2015.txt', 'bctech2056.txt', 'bctech2092.txt', 'bctech2075.txt', 'bctech2104.txt', 'bctech2148.txt', 'bctech2096.txt', 'bctech2144.txt', 'bctech2153.txt', 'bctech2019.txt', 'bctech2062.txt', 'bctech2044.txt', 'bctech2046.txt', 'bctech2029.txt', 'bctech2047.txt', 'bctech2152.txt', 'bctech2018.txt', 'bctech2041.txt', 'bctech2091.txt', 'bctech2081.txt', 'bctech2039.txt', 'bctech2057.txt', 'bctech2024.txt', 'bctech2147.txt', 'bctech2098.txt', 'bctech2117.txt', 'bctech2069.txt', 'bctech2048.txt', 'bctech2115.txt', 'bctech2105.txt', 'bctech2028.txt', 'bctech2122.txt', 'bctech2136.txt', 'bctech2054.txt', 'bctech2026.txt', 'bctech2156.txt', 'bctech2043.txt', 'bctech2140.txt', 'bctech2042.txt', 'bctech2072.txt', 'bctech2032.txt', 'bctech2120.txt', 'bctech2128.txt', 'bctech2014.txt', 'bctech2074.txt', 'bctech2137.txt', 'bctech2061.txt', 'bctech2123.txt', 'bctech2113.txt', 'bctech2060.txt', 'bctech2133.txt', 'bctech2095.txt', 'bctech2102.txt', 'bctech2124.txt', 'bctech2100.txt', 'bctech2143.txt', 'bctech2088.txt', 'bctech2065.txt', 'bctech2038.txt', 'bctech2071.txt', 'bctech2149.txt', 'bctech2125.txt', 'bctech2103.txt', 'bctech2099.txt', 'bctech2067.txt', 'bctech2109.txt', 'bctech2085.txt', 'bctech2078.txt', 'bctech2045.txt', 'bctech2035.txt', 'bctech2141.txt', 'bctech2093.txt', 'bctech2021.txt', 'bctech2154.txt', 'bctech2127.txt', 'bctech2051.txt', 'bctech2059.txt', 'bctech2016.txt', 'bctech2070.txt', 'bctech2052.txt', 'bctech2040.txt', 'bctech2027.txt', 'bctech2030.txt', 'bctech2101.txt', 'bctech2157.txt', 'bctech2077.txt', 'bctech2131.txt']\n",
            "Healthcare Data Analysis\n",
            "\n",
            "Client:A leading healthcare tech firm in the USA\n",
            "Industry Type:Healthcare Consulting\n",
            "Services:Management consultant\n",
            "Organization Size:100+\n",
            "The main objective of this project is to find the pattern in the vital signs of patients who were admitted to the hospital in past. And from this pattern, we get some ranges that help us to give early warnings.\n",
            "We are more interested in non-survivor patients’ vital signs as compare to survivor patients. we find patterns invital signsthat could better determine that patient died (ex. if Sp02 is below 70, patient in 95% of cases died, if Sp02 is below 50%, the death rate is 99.9%) or we can take correlations which can help us to find better patterns to define death cases.\n",
            "Data The dataset which was used for analysis here is taken from the mimic website. But the dataset is not in the correct format which we want, after some manipulation, we get the data ready for the analysis.\n",
            "Approach\n",
            "I can’t go with 1st option because a major part of the data has missing values. so, I decided to go with the second option and fill missing values with the average of upper and lower values. But before that, I filtered the data and take only those patients’ data who died in a hospital or survive.\n",
            "SQL\n",
            "MongoDB\n",
            "Google Cloud\n",
            "https://colab.research.google.com/drive/1mo7i32BoEVb0Ac6_CWwJd7_HVbliktx0?usp=sharing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "# List all .txt files\n",
        "extracted_files = [f for f in os.listdir() if f.endswith('.txt')]\n",
        "print(\"Extracted files:\", extracted_files)\n",
        "\n",
        "# Create a zip file\n",
        "with zipfile.ZipFile('extracted_files.zip', 'w') as zipf:\n",
        "    for file in extracted_files:\n",
        "        zipf.write(file)\n",
        "\n",
        "# Download the zip file\n",
        "files.download('extracted_files.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "YvA-JcyVVdf7",
        "outputId": "d78a4568-9101-4eb2-ca83-93edc0d1ad6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['bctech2129.txt', 'bctech2086.txt', 'bctech2034.txt', 'bctech2135.txt', 'bctech2049.txt', 'bctech2138.txt', 'bctech2084.txt', 'bctech2142.txt', 'bctech2025.txt', 'bctech2083.txt', 'bctech2108.txt', 'bctech2080.txt', 'bctech2013.txt', 'bctech2132.txt', 'bctech2089.txt', 'bctech2063.txt', 'bctech2094.txt', 'bctech2146.txt', 'bctech2053.txt', 'bctech2012.txt', 'bctech2082.txt', 'bctech2011.txt', 'bctech2145.txt', 'bctech2033.txt', 'bctech2079.txt', 'bctech2139.txt', 'bctech2031.txt', 'bctech2058.txt', 'bctech2076.txt', 'bctech2073.txt', 'bctech2150.txt', 'bctech2119.txt', 'bctech2114.txt', 'bctech2090.txt', 'bctech2036.txt', 'bctech2097.txt', 'bctech2037.txt', 'bctech2151.txt', 'bctech2130.txt', 'bctech2134.txt', 'bctech2064.txt', 'bctech2068.txt', 'bctech2121.txt', 'bctech2111.txt', 'bctech2066.txt', 'bctech2126.txt', 'bctech2020.txt', 'bctech2107.txt', 'bctech2050.txt', 'bctech2055.txt', 'bctech2155.txt', 'bctech2022.txt', 'bctech2087.txt', 'bctech2116.txt', 'bctech2118.txt', 'bctech2017.txt', 'bctech2023.txt', 'bctech2106.txt', 'bctech2110.txt', 'bctech2112.txt', 'bctech2015.txt', 'bctech2056.txt', 'bctech2092.txt', 'bctech2075.txt', 'bctech2104.txt', 'bctech2148.txt', 'bctech2096.txt', 'bctech2144.txt', 'bctech2153.txt', 'bctech2019.txt', 'bctech2062.txt', 'bctech2044.txt', 'bctech2046.txt', 'bctech2029.txt', 'bctech2047.txt', 'bctech2152.txt', 'bctech2018.txt', 'bctech2041.txt', 'bctech2091.txt', 'bctech2081.txt', 'bctech2039.txt', 'bctech2057.txt', 'bctech2024.txt', 'bctech2147.txt', 'bctech2098.txt', 'bctech2117.txt', 'bctech2069.txt', 'bctech2048.txt', 'bctech2115.txt', 'bctech2105.txt', 'bctech2028.txt', 'bctech2122.txt', 'bctech2136.txt', 'bctech2054.txt', 'bctech2026.txt', 'bctech2156.txt', 'bctech2043.txt', 'bctech2140.txt', 'bctech2042.txt', 'bctech2072.txt', 'bctech2032.txt', 'bctech2120.txt', 'bctech2128.txt', 'bctech2014.txt', 'bctech2074.txt', 'bctech2137.txt', 'bctech2061.txt', 'bctech2123.txt', 'bctech2113.txt', 'bctech2060.txt', 'bctech2133.txt', 'bctech2095.txt', 'bctech2102.txt', 'bctech2124.txt', 'bctech2100.txt', 'bctech2143.txt', 'bctech2088.txt', 'bctech2065.txt', 'bctech2038.txt', 'bctech2071.txt', 'bctech2149.txt', 'bctech2125.txt', 'bctech2103.txt', 'bctech2099.txt', 'bctech2067.txt', 'bctech2109.txt', 'bctech2085.txt', 'bctech2078.txt', 'bctech2045.txt', 'bctech2035.txt', 'bctech2141.txt', 'bctech2093.txt', 'bctech2021.txt', 'bctech2154.txt', 'bctech2127.txt', 'bctech2051.txt', 'bctech2059.txt', 'bctech2016.txt', 'bctech2070.txt', 'bctech2052.txt', 'bctech2040.txt', 'bctech2027.txt', 'bctech2030.txt', 'bctech2101.txt', 'bctech2157.txt', 'bctech2077.txt', 'bctech2131.txt']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ceb93cba-012d-4194-9d33-383ac23791a0\", \"extracted_files.zip\", 286337)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Analysis"
      ],
      "metadata": {
        "id": "ZLaA06_i9lHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob pyphen\n",
        "!python -m textblob.download_corpora\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxZxojpuAh6n",
        "outputId": "9935e147-57e9-48f1-d148-66a9dcf8f86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Collecting pyphen\n",
            "  Downloading pyphen-0.15.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.4)\n",
            "Installing collected packages: pyphen\n",
            "Successfully installed pyphen-0.15.0\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from textblob import TextBlob\n",
        "import pyphen\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def count_syllables(word):\n",
        "    dic = pyphen.Pyphen(lang='en')\n",
        "    return len(dic.inserted(word).split('-'))\n",
        "\n",
        "def analyze_text(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentences = blob.sentences\n",
        "    words = blob.words\n",
        "\n",
        "    positive_score = sum([1 for word in words if TextBlob(word).sentiment.polarity > 0])\n",
        "    negative_score = sum([1 for word in words if TextBlob(word).sentiment.polarity < 0])\n",
        "    polarity_score = blob.sentiment.polarity\n",
        "    subjectivity_score = blob.sentiment.subjectivity\n",
        "    avg_sentence_length = sum(len(sentence.words) for sentence in sentences) / len(sentences)\n",
        "    complex_words = [word for word in words if count_syllables(word) > 2]\n",
        "    percentage_complex_words = len(complex_words) / len(words) * 100\n",
        "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
        "    avg_words_per_sentence = len(words) / len(sentences)\n",
        "    word_count = len(words)\n",
        "    syllables_per_word = sum(count_syllables(word) for word in words) / len(words)\n",
        "    personal_pronouns = sum(1 for word in words if word.lower() in ['i', 'we', 'my', 'ours', 'us'])\n",
        "    avg_word_length = sum(len(word) for word in words) / len(words)\n",
        "\n",
        "    return {\n",
        "        \"Positive Score\": positive_score,\n",
        "        \"Negative Score\": negative_score,\n",
        "        \"Polarity Score\": polarity_score,\n",
        "        \"Subjectivity Score\": subjectivity_score,\n",
        "        \"Avg Sentence Length\": avg_sentence_length,\n",
        "        \"Percentage of Complex Words\": percentage_complex_words,\n",
        "        \"Fog Index\": fog_index,\n",
        "        \"Avg Number of Words Per Sentence\": avg_words_per_sentence,\n",
        "        \"Complex Word Count\": len(complex_words),\n",
        "        \"Word Count\": word_count,\n",
        "        \"Syllables per Word\": syllables_per_word,\n",
        "        \"Personal Pronouns\": personal_pronouns,\n",
        "        \"Avg Word Length\": avg_word_length,\n",
        "    }\n",
        "\n",
        "# Upload the example text file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Example usage:\n",
        "with open('/content/bctech2139.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "    analysis_result = analyze_text(text)\n",
        "    print(analysis_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "5nM77_65AmyX",
        "outputId": "099b1b9f-9bfc-4bea-9256-6cc4ddd1f502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cceca023-d327-4d99-8a29-f749f1989fd3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cceca023-d327-4d99-8a29-f749f1989fd3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bctech2139.txt to bctech2139 (2).txt\n",
            "{'Positive Score': 10, 'Negative Score': 5, 'Polarity Score': 0.050106837606837616, 'Subjectivity Score': 0.48450854700854695, 'Avg Sentence Length': 20.166666666666668, 'Percentage of Complex Words': 14.600550964187327, 'Fog Index': 13.906887052341597, 'Avg Number of Words Per Sentence': 20.166666666666668, 'Complex Word Count': 53, 'Word Count': 363, 'Syllables per Word': 1.581267217630854, 'Personal Pronouns': 12, 'Avg Word Length': 5.2727272727272725}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob pyphen pandas\n",
        "!python -m textblob.download_corpora\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3559C4xpWogf",
        "outputId": "e756ee65-9282-4f3b-c09d-6a5517700eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from textblob import TextBlob\n",
        "import pyphen\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def count_syllables(word):\n",
        "    dic = pyphen.Pyphen(lang='en')\n",
        "    return len(dic.inserted(word).split('-'))\n",
        "\n",
        "def analyze_text(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentences = blob.sentences\n",
        "    words = blob.words\n",
        "\n",
        "    positive_score = sum([1 for word in words if TextBlob(word).sentiment.polarity > 0])\n",
        "    negative_score = sum([1 for word in words if TextBlob(word).sentiment.polarity < 0])\n",
        "    polarity_score = blob.sentiment.polarity\n",
        "    subjectivity_score = blob.sentiment.subjectivity\n",
        "    avg_sentence_length = sum(len(sentence.words) for sentence in sentences) / len(sentences)\n",
        "    complex_words = [word for word in words if count_syllables(word) > 2]\n",
        "    percentage_complex_words = len(complex_words) / len(words) * 100\n",
        "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
        "    avg_words_per_sentence = len(words) / len(sentences)\n",
        "    word_count = len(words)\n",
        "    syllables_per_word = sum(count_syllables(word) for word in words) / len(words)\n",
        "    personal_pronouns = sum(1 for word in words if word.lower() in ['i', 'we', 'my', 'ours', 'us'])\n",
        "    avg_word_length = sum(len(word) for word in words) / len(words)\n",
        "\n",
        "    return {\n",
        "        \"Positive Score\": positive_score,\n",
        "        \"Negative Score\": negative_score,\n",
        "        \"Polarity Score\": polarity_score,\n",
        "        \"Subjectivity Score\": subjectivity_score,\n",
        "        \"Avg Sentence Length\": avg_sentence_length,\n",
        "        \"Percentage of Complex Words\": percentage_complex_words,\n",
        "        \"Fog Index\": fog_index,\n",
        "        \"Avg Number of Words Per Sentence\": avg_words_per_sentence,\n",
        "        \"Complex Word Count\": len(complex_words),\n",
        "        \"Word Count\": word_count,\n",
        "        \"Syllables per Word\": syllables_per_word,\n",
        "        \"Personal Pronouns\": personal_pronouns,\n",
        "        \"Avg Word Length\": avg_word_length,\n",
        "    }\n",
        "\n",
        "# Function to process all text files and save to CSV\n",
        "def process_files_and_save_to_csv():\n",
        "    results = []\n",
        "\n",
        "    # List all text files in the current directory\n",
        "    text_files = [f for f in os.listdir() if f.endswith('.txt')]\n",
        "\n",
        "    for file_name in text_files:\n",
        "        with open(file_name, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "            analysis_result = analyze_text(text)\n",
        "            analysis_result['File Name'] = file_name\n",
        "            results.append(analysis_result)\n",
        "\n",
        "    # Convert results to DataFrame and save to CSV\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv('analysis_results.csv', index=False)\n",
        "    print(\"Analysis complete! Results saved to 'analysis_results.csv'\")\n",
        "\n",
        "# Upload the text files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Run the analysis and save results\n",
        "process_files_and_save_to_csv()\n",
        "\n",
        "# Display the first few rows of the result\n",
        "df = pd.read_csv('analysis_results.csv')\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gdiqHgYaWuoM",
        "outputId": "e4567cd4-5bdc-4904-f7ea-547d89c360bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0e1e62db-266b-43bc-a63d-bb8f7a16506b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0e1e62db-266b-43bc-a63d-bb8f7a16506b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bctech2016.txt to bctech2016 (1).txt\n",
            "Saving bctech2027.txt to bctech2027 (1).txt\n",
            "Saving bctech2030.txt to bctech2030 (1).txt\n",
            "Saving bctech2040.txt to bctech2040 (1).txt\n",
            "Saving bctech2051.txt to bctech2051 (1).txt\n",
            "Saving bctech2052.txt to bctech2052 (1).txt\n",
            "Saving bctech2059.txt to bctech2059 (1).txt\n",
            "Saving bctech2070.txt to bctech2070 (1).txt\n",
            "Saving bctech2077.txt to bctech2077 (1).txt\n",
            "Saving bctech2101.txt to bctech2101 (1).txt\n",
            "Saving bctech2127.txt to bctech2127 (1).txt\n",
            "Saving bctech2131.txt to bctech2131 (1).txt\n",
            "Saving bctech2154.txt to bctech2154 (1).txt\n",
            "Saving bctech2157.txt to bctech2157 (1).txt\n",
            "Saving bctech2021.txt to bctech2021 (1).txt\n",
            "Saving bctech2035.txt to bctech2035 (1).txt\n",
            "Saving bctech2038.txt to bctech2038 (1).txt\n",
            "Saving bctech2045.txt to bctech2045 (1).txt\n",
            "Saving bctech2065.txt to bctech2065 (1).txt\n",
            "Saving bctech2071.txt to bctech2071 (1).txt\n",
            "Saving bctech2078.txt to bctech2078 (1).txt\n",
            "Saving bctech2085.txt to bctech2085 (1).txt\n",
            "Saving bctech2093.txt to bctech2093 (1).txt\n",
            "Saving bctech2099.txt to bctech2099 (1).txt\n",
            "Saving bctech2103.txt to bctech2103 (1).txt\n",
            "Saving bctech2109.txt to bctech2109 (1).txt\n",
            "Saving bctech2125.txt to bctech2125 (1).txt\n",
            "Saving bctech2141.txt to bctech2141 (1).txt\n",
            "Saving bctech2149.txt to bctech2149 (1).txt\n",
            "Saving bctech2014.txt to bctech2014 (1).txt\n",
            "Saving bctech2060.txt to bctech2060 (1).txt\n",
            "Saving bctech2061.txt to bctech2061 (1).txt\n",
            "Saving bctech2074.txt to bctech2074 (1).txt\n",
            "Saving bctech2088.txt to bctech2088 (1).txt\n",
            "Saving bctech2095.txt to bctech2095 (1).txt\n",
            "Saving bctech2100.txt to bctech2100 (1).txt\n",
            "Saving bctech2102.txt to bctech2102 (1).txt\n",
            "Saving bctech2113.txt to bctech2113 (1).txt\n",
            "Saving bctech2120.txt to bctech2120 (1).txt\n",
            "Saving bctech2123.txt to bctech2123 (1).txt\n",
            "Saving bctech2124.txt to bctech2124 (1).txt\n",
            "Saving bctech2128.txt to bctech2128 (1).txt\n",
            "Saving bctech2133.txt to bctech2133 (1).txt\n",
            "Saving bctech2137.txt to bctech2137 (1).txt\n",
            "Saving bctech2143.txt to bctech2143 (1).txt\n",
            "Saving bctech2026.txt to bctech2026 (1).txt\n",
            "Saving bctech2028.txt to bctech2028 (1).txt\n",
            "Saving bctech2032.txt to bctech2032 (1).txt\n",
            "Saving bctech2042.txt to bctech2042 (1).txt\n",
            "Saving bctech2043.txt to bctech2043 (1).txt\n",
            "Saving bctech2048.txt to bctech2048 (1).txt\n",
            "Saving bctech2054.txt to bctech2054 (1).txt\n",
            "Saving bctech2069.txt to bctech2069 (1).txt\n",
            "Saving bctech2072.txt to bctech2072 (1).txt\n",
            "Saving bctech2098.txt to bctech2098 (1).txt\n",
            "Saving bctech2105.txt to bctech2105 (1).txt\n",
            "Saving bctech2115.txt to bctech2115 (1).txt\n",
            "Saving bctech2117.txt to bctech2117 (1).txt\n",
            "Saving bctech2122.txt to bctech2122 (1).txt\n",
            "Saving bctech2136.txt to bctech2136 (1).txt\n",
            "Saving bctech2140.txt to bctech2140 (1).txt\n",
            "Saving bctech2147.txt to bctech2147 (1).txt\n",
            "Saving bctech2156.txt to bctech2156 (1).txt\n",
            "Saving bctech2018.txt to bctech2018 (1).txt\n",
            "Saving bctech2019.txt to bctech2019 (1).txt\n",
            "Saving bctech2024.txt to bctech2024 (1).txt\n",
            "Saving bctech2029.txt to bctech2029 (1).txt\n",
            "Saving bctech2039.txt to bctech2039 (1).txt\n",
            "Saving bctech2041.txt to bctech2041 (1).txt\n",
            "Saving bctech2044.txt to bctech2044 (1).txt\n",
            "Saving bctech2046.txt to bctech2046 (1).txt\n",
            "Saving bctech2047.txt to bctech2047 (1).txt\n",
            "Saving bctech2057.txt to bctech2057 (1).txt\n",
            "Saving bctech2062.txt to bctech2062 (1).txt\n",
            "Saving bctech2081.txt to bctech2081 (1).txt\n",
            "Saving bctech2091.txt to bctech2091 (1).txt\n",
            "Saving bctech2096.txt to bctech2096 (1).txt\n",
            "Saving bctech2144.txt to bctech2144 (1).txt\n",
            "Saving bctech2148.txt to bctech2148 (1).txt\n",
            "Saving bctech2152.txt to bctech2152 (1).txt\n",
            "Saving bctech2153.txt to bctech2153 (1).txt\n",
            "Saving bctech2015.txt to bctech2015 (1).txt\n",
            "Saving bctech2017.txt to bctech2017 (1).txt\n",
            "Saving bctech2020.txt to bctech2020 (1).txt\n",
            "Saving bctech2022.txt to bctech2022 (1).txt\n",
            "Saving bctech2023.txt to bctech2023 (1).txt\n",
            "Saving bctech2050.txt to bctech2050 (1).txt\n",
            "Saving bctech2055.txt to bctech2055 (1).txt\n",
            "Saving bctech2056.txt to bctech2056 (1).txt\n",
            "Saving bctech2075.txt to bctech2075 (1).txt\n",
            "Saving bctech2087.txt to bctech2087 (1).txt\n",
            "Saving bctech2092.txt to bctech2092 (1).txt\n",
            "Saving bctech2104.txt to bctech2104 (1).txt\n",
            "Saving bctech2106.txt to bctech2106 (1).txt\n",
            "Saving bctech2107.txt to bctech2107 (1).txt\n",
            "Saving bctech2110.txt to bctech2110 (1).txt\n",
            "Saving bctech2112.txt to bctech2112 (1).txt\n",
            "Saving bctech2116.txt to bctech2116 (1).txt\n",
            "Saving bctech2118.txt to bctech2118 (1).txt\n",
            "Saving bctech2155.txt to bctech2155 (1).txt\n",
            "Saving bctech2036.txt to bctech2036 (1).txt\n",
            "Saving bctech2037.txt to bctech2037 (1).txt\n",
            "Saving bctech2064.txt to bctech2064 (1).txt\n",
            "Saving bctech2066.txt to bctech2066 (1).txt\n",
            "Saving bctech2068.txt to bctech2068 (1).txt\n",
            "Saving bctech2073.txt to bctech2073 (1).txt\n",
            "Saving bctech2076.txt to bctech2076 (1).txt\n",
            "Saving bctech2090.txt to bctech2090 (1).txt\n",
            "Saving bctech2097.txt to bctech2097 (1).txt\n",
            "Saving bctech2111.txt to bctech2111 (1).txt\n",
            "Saving bctech2114.txt to bctech2114 (1).txt\n",
            "Saving bctech2119.txt to bctech2119 (1).txt\n",
            "Saving bctech2121.txt to bctech2121 (1).txt\n",
            "Saving bctech2126.txt to bctech2126 (1).txt\n",
            "Saving bctech2130.txt to bctech2130 (1).txt\n",
            "Saving bctech2134.txt to bctech2134 (1).txt\n",
            "Saving bctech2150.txt to bctech2150 (1).txt\n",
            "Saving bctech2151.txt to bctech2151 (1).txt\n",
            "Saving bctech2011.txt to bctech2011 (1).txt\n",
            "Saving bctech2012.txt to bctech2012 (1).txt\n",
            "Saving bctech2013.txt to bctech2013 (1).txt\n",
            "Saving bctech2031.txt to bctech2031 (1).txt\n",
            "Saving bctech2033.txt to bctech2033 (1).txt\n",
            "Saving bctech2053.txt to bctech2053 (1).txt\n",
            "Saving bctech2058.txt to bctech2058 (1).txt\n",
            "Saving bctech2063.txt to bctech2063 (1).txt\n",
            "Saving bctech2079.txt to bctech2079 (1).txt\n",
            "Saving bctech2082.txt to bctech2082 (1).txt\n",
            "Saving bctech2089.txt to bctech2089 (1).txt\n",
            "Saving bctech2094.txt to bctech2094 (1).txt\n",
            "Saving bctech2132.txt to bctech2132 (1).txt\n",
            "Saving bctech2139.txt to bctech2139 (1).txt\n",
            "Saving bctech2145.txt to bctech2145 (1).txt\n",
            "Saving bctech2146.txt to bctech2146 (1).txt\n",
            "Saving bctech2025.txt to bctech2025 (1).txt\n",
            "Saving bctech2034.txt to bctech2034 (1).txt\n",
            "Saving bctech2049.txt to bctech2049 (1).txt\n",
            "Saving bctech2080.txt to bctech2080 (1).txt\n",
            "Saving bctech2083.txt to bctech2083 (1).txt\n",
            "Saving bctech2084.txt to bctech2084 (1).txt\n",
            "Saving bctech2086.txt to bctech2086 (1).txt\n",
            "Saving bctech2108.txt to bctech2108 (1).txt\n",
            "Saving bctech2129.txt to bctech2129 (1).txt\n",
            "Saving bctech2135.txt to bctech2135 (1).txt\n",
            "Saving bctech2138.txt to bctech2138 (1).txt\n",
            "Saving bctech2142.txt to bctech2142 (1).txt\n",
            "Analysis complete! Results saved to 'analysis_results.csv'\n",
            "   Positive Score  Negative Score  Polarity Score  Subjectivity Score  \\\n",
            "0               1               0        0.100000            0.300000   \n",
            "1              17               2        0.160422            0.434206   \n",
            "2               1               0        0.100000            0.300000   \n",
            "3               5               5        0.031760            0.261735   \n",
            "4              13               4        0.146154            0.570367   \n",
            "\n",
            "   Avg Sentence Length  Percentage of Complex Words  Fog Index  \\\n",
            "0            49.000000                    32.653061  32.661224   \n",
            "1            20.617647                    19.115549  15.893279   \n",
            "2            49.000000                    32.653061  32.661224   \n",
            "3            20.416667                    15.102041  14.207483   \n",
            "4            22.133333                    18.373494  16.202731   \n",
            "\n",
            "   Avg Number of Words Per Sentence  Complex Word Count  Word Count  \\\n",
            "0                         49.000000                  16          49   \n",
            "1                         20.617647                 134         701   \n",
            "2                         49.000000                  16          49   \n",
            "3                         20.416667                  37         245   \n",
            "4                         22.133333                  61         332   \n",
            "\n",
            "   Syllables per Word  Personal Pronouns  Avg Word Length           File Name  \n",
            "0            2.571429                  0        13.183673      bctech2129.txt  \n",
            "1            1.713267                  6         5.751783  bctech2081 (1).txt  \n",
            "2            2.571429                  0        13.183673  bctech2129 (1).txt  \n",
            "3            1.661224                  5         5.481633      bctech2086.txt  \n",
            "4            1.759036                  1         5.936747      bctech2034.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('analysis_results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "a5g9agOjYv6J",
        "outputId": "2588de7c-a8ca-4574-88b1-5115b9077b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8a7a3087-91c3-4e0c-b7fc-406edbd2fbd8\", \"analysis_results.csv\", 48875)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}